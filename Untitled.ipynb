{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7516defe-3c44-4733-b394-a3f599f30a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/24 11:02:55 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, PCA\n",
    "from pyspark.ml.clustering import KMeans, BisectingKMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.sql.functions import col, isnan, when, count, mean, min, max, stddev, percentile_approx\n",
    "from pyspark.ml.stat import Correlation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pyspark.sql.types import DoubleType\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MultiBehaviorCustomerSegmentation\") \\\n",
    "    .config(\"spark.driver.memory\", \"30g\") \\\n",
    "    .config(\"spark.executor.memory\", \"30g\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"18g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"18g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.dynamicAllocation.minExecutors\", \"2\") \\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"10\") \\\n",
    "    .config(\"spark.dynamicAllocation.initialExecutors\", \"4\") \\\n",
    "    .config(\"spark.default.parallelism\", \"200\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6ad93a-0546-4191-9c96-1ca03ba4a01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Load and Clean Data\n",
    "# ---------------------\n",
    "df = spark.read.csv(\"ctzn_2_years_data.csv\", header=True, inferSchema=True)\n",
    "df = df.na.fill(0)\n",
    "\n",
    "# ---------------------\n",
    "# 3. Define Cluster Types\n",
    "# ---------------------\n",
    "cluster_configs = {\n",
    "    \"spending\": {\n",
    "        \"features\": [\n",
    "            \"purchases\", \"oneoff_purchases\", \"installments_purchases\",\n",
    "            \"purchases_frequency\", \"oneoff_purchases_frequency\", \"purchases_installments_frequency\"\n",
    "        ],\n",
    "        \"k\": 5\n",
    "    },\n",
    "    \"cash\": {\n",
    "        \"features\": [\"cash_advance\", \"cash_advance_frequency\", \"cash_advance_trx\"],\n",
    "        \"k\": 4\n",
    "    },\n",
    "    \"payment\": {\n",
    "        \"features\": [\"payments\", \"minimum_payments\", \"prc_full_payment\", \"tenure\"],\n",
    "        \"k\": 4\n",
    "    },\n",
    "    \"credit\": {\n",
    "        \"features\": [\"balance\", \"credit_limit\"],\n",
    "        \"k\": 4\n",
    "    },\n",
    "    \"health\": {\n",
    "        \"features\": [\"balance\", \"purchases\", \"payments\", \"cash_advance\", \"credit_limit\"],\n",
    "        \"k\": 4\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e928e85-5a99-4189-8e10-e4be25ca4dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add derived feature for credit utilization\n",
    "df = df.withColumn(\"balance_credit_ratio\", when(col(\"credit_limit\") != 0, col(\"balance\") / col(\"credit_limit\")).otherwise(0))\n",
    "cluster_configs[\"credit\"][\"features\"].append(\"balance_credit_ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5561ea18-2a4e-432d-96a2-36b7e8e3c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "\n",
    "# 4. Function: Run Clustering\n",
    "# ---------------------\n",
    "def run_clustering(df, id_col, cluster_name, feature_cols, k):\n",
    "    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "    assembled = assembler.transform(df.select(id_col, *feature_cols))\n",
    "\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "    scaled = scaler.fit(assembled).transform(assembled)\n",
    "\n",
    "    pca = PCA(k=builtins.min(2, len(feature_cols)), inputCol=\"scaled_features\", outputCol=\"pca_features\")\n",
    "    pca_data = pca.fit(scaled).transform(scaled)\n",
    "\n",
    "    # kmeans = KMeans(k=k, seed=42, featuresCol=\"pca_features\")\n",
    "    kmeans = KMeans(k=k, seed=42, featuresCol=\"scaled_features\")\n",
    "    model = kmeans.fit(pca_data)\n",
    "    clustered = model.transform(pca_data)\n",
    "\n",
    "    # Extract only required columns\n",
    "    return clustered.select(id_col, col(\"prediction\").alias(f\"{cluster_name}_cluster\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e07119-c7d0-497b-9f99-e114393bf29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering: spending\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering: cash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering: payment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering: credit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering: health\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# 5. Run All Clusterings\n",
    "# ---------------------\n",
    "cluster_results = []\n",
    "for cluster_name, config in cluster_configs.items():\n",
    "    print(f\"Clustering: {cluster_name}\")\n",
    "    result = run_clustering(df, \"cif_id\", cluster_name, config[\"features\"], config[\"k\"])\n",
    "    cluster_results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb27612-187d-4727-b93a-027a9ce9cf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: multi_behavior_customer_segments.csv\n"
     ]
    }
   ],
   "source": [
    "# 6. Join All Results on cif_id\n",
    "# ---------------------\n",
    "final_clusters = cluster_results[0]\n",
    "for cluster_df in cluster_results[1:]:\n",
    "    final_clusters = final_clusters.join(cluster_df, on=\"cif_id\", how=\"inner\")\n",
    "\n",
    "# ---------------------\n",
    "# 7. Convert to Pandas and Save\n",
    "# ---------------------\n",
    "final_clusters_pd = final_clusters.toPandas()\n",
    "final_clusters_pd.to_csv(\"multi_behavior_customer_segments.csv\", index=False)\n",
    "\n",
    "print(\"Saved: multi_behavior_customer_segments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbcb1506-1551-49c3-8ba8-f8b2a1c68305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_clusters(df, id_col, cluster_col, feature_cols, cluster_name):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    - cluster_profiles: per-cluster mean values of features\n",
    "    - relative_importance: % difference from average\n",
    "    - descriptions: business labels per cluster\n",
    "    \"\"\"\n",
    "    # Prepare\n",
    "    cluster_df = df.select(cluster_col, *feature_cols)\n",
    "    for c in feature_cols:\n",
    "        cluster_df = cluster_df.withColumn(c, col(c).cast(\"double\"))\n",
    "\n",
    "    pandas_df = cluster_df.toPandas()\n",
    "\n",
    "    # Mean feature values per cluster\n",
    "    cluster_profiles = pandas_df.groupby(cluster_col).mean()\n",
    "    overall_means = pandas_df[feature_cols].mean()\n",
    "\n",
    "    # Relative importance\n",
    "    relative_importance = cluster_profiles.copy()\n",
    "    for col_name in feature_cols:\n",
    "        overall = overall_means[col_name]\n",
    "        if overall != 0:\n",
    "            relative_importance[col_name] = (cluster_profiles[col_name] - overall) / overall\n",
    "        else:\n",
    "            relative_importance[col_name] = cluster_profiles[col_name] - overall\n",
    "\n",
    "    # Build descriptions\n",
    "    descriptions = {}\n",
    "    for cluster_id in cluster_profiles.index:\n",
    "        desc = []\n",
    "        top_features = relative_importance.loc[cluster_id].abs().sort_values(ascending=False).head(3).index\n",
    "        for feat in top_features:\n",
    "            val = relative_importance.loc[cluster_id, feat]\n",
    "            direction = \"higher\" if val > 0 else \"lower\"\n",
    "            desc.append(f\"{feat} is {abs(val)*100:.1f}% {direction} than average\")\n",
    "        descriptions[cluster_id] = f\"{cluster_name.capitalize()} Cluster {cluster_id}: \" + \"; \".join(desc)\n",
    "\n",
    "    return cluster_profiles, relative_importance, descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b21df83-df7a-4082-86e9-3034fc6d27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spending Cluster 0: oneoff_purchases_frequency is 100.0% lower than average; installments_purchases is 62.9% lower than average; purchases is 59.8% lower than average\n",
      "Spending Cluster 1: installments_purchases is 760642.6% higher than average; purchases is 694571.1% higher than average; oneoff_purchases is 481756.0% higher than average\n",
      "Spending Cluster 2: installments_purchases is 180925.0% higher than average; purchases is 176204.6% higher than average; oneoff_purchases is 161000.4% higher than average\n",
      "Spending Cluster 3: oneoff_purchases_frequency is 4187.5% higher than average; installments_purchases is 72.7% lower than average; oneoff_purchases is 57.6% higher than average\n",
      "Spending Cluster 4: purchases_frequency is 148516.7% higher than average; oneoff_purchases is 6397.8% higher than average; purchases is 3452.4% higher than average\n"
     ]
    }
   ],
   "source": [
    "# Example for spending\n",
    "spending_cluster_df = df.join(cluster_results[0], on=\"cif_id\")\n",
    "spending_profiles, spending_rel, spending_desc = interpret_clusters(\n",
    "    df=spending_cluster_df,\n",
    "    id_col=\"cif_id\",\n",
    "    cluster_col=\"spending_cluster\",\n",
    "    feature_cols=cluster_configs[\"spending\"][\"features\"],\n",
    "    cluster_name=\"spending\"\n",
    ")\n",
    "\n",
    "# Print results\n",
    "for cid, desc in spending_desc.items():\n",
    "    print(desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f8e5d51-a39f-4ae6-bd03-2a0073830057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š SPENDING CLUSTER INTERPRETATIONS:\n",
      "- Cluster 0: Spending Cluster 0: oneoff_purchases_frequency is 100.0% lower than average; installments_purchases is 62.9% lower than average; purchases is 59.8% lower than average\n",
      "- Cluster 1: Spending Cluster 1: installments_purchases is 760642.6% higher than average; purchases is 694571.1% higher than average; oneoff_purchases is 481756.0% higher than average\n",
      "- Cluster 2: Spending Cluster 2: installments_purchases is 180925.0% higher than average; purchases is 176204.6% higher than average; oneoff_purchases is 161000.4% higher than average\n",
      "- Cluster 3: Spending Cluster 3: oneoff_purchases_frequency is 4187.5% higher than average; installments_purchases is 72.7% lower than average; oneoff_purchases is 57.6% higher than average\n",
      "- Cluster 4: Spending Cluster 4: purchases_frequency is 148516.7% higher than average; oneoff_purchases is 6397.8% higher than average; purchases is 3452.4% higher than average\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š CASH CLUSTER INTERPRETATIONS:\n",
      "- Cluster 0: Cash Cluster 0: cash_advance_frequency is 100.0% lower than average; cash_advance is 85.5% lower than average; cash_advance_trx is 47.6% lower than average\n",
      "- Cluster 1: Cash Cluster 1: cash_advance_frequency is 32.6% higher than average; cash_advance is 31.7% lower than average; cash_advance_trx is 31.5% lower than average\n",
      "- Cluster 2: Cash Cluster 2: cash_advance_trx is 2202.6% higher than average; cash_advance is 2037.4% higher than average; cash_advance_frequency is 8.7% higher than average\n",
      "- Cluster 3: Cash Cluster 3: cash_advance is 5846995.0% higher than average; cash_advance_trx is 4663.6% higher than average; cash_advance_frequency is 32.6% higher than average\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š PAYMENT CLUSTER INTERPRETATIONS:\n",
      "- Cluster 0: Payment Cluster 0: prc_full_payment is 100.0% lower than average; minimum_payments is 80.2% lower than average; payments is 17.4% lower than average\n",
      "- Cluster 1: Payment Cluster 1: minimum_payments is 380969.4% higher than average; payments is 97.7% lower than average; prc_full_payment is 1.7% lower than average\n",
      "- Cluster 2: Payment Cluster 2: minimum_payments is 79.9% lower than average; payments is 77.6% lower than average; tenure is 72.9% higher than average\n",
      "- Cluster 3: Payment Cluster 3: minimum_payments is 79.7% lower than average; prc_full_payment is 51.9% higher than average; payments is 47.0% higher than average\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š CREDIT CLUSTER INTERPRETATIONS:\n",
      "- Cluster 0: Credit Cluster 0: balance is 137.8% higher than average; balance_credit_ratio is 83.8% lower than average; credit_limit is 79.9% lower than average\n",
      "- Cluster 1: Credit Cluster 1: balance_credit_ratio is 40753617.6% higher than average; balance is 7062.8% higher than average; credit_limit is 100.0% lower than average\n",
      "- Cluster 2: Credit Cluster 2: credit_limit is 380969.4% higher than average; balance is 568.9% lower than average; balance_credit_ratio is 100.0% lower than average\n",
      "- Cluster 3: Credit Cluster 3: balance is 16731792.4% lower than average; credit_limit is 100.0% lower than average; balance_credit_ratio is 100.0% lower than average\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š HEALTH CLUSTER INTERPRETATIONS:\n",
      "- Cluster 0: Health Cluster 0: balance is 137.7% higher than average; credit_limit is 79.9% lower than average; cash_advance is 12.0% lower than average\n",
      "- Cluster 1: Health Cluster 1: balance is 16731792.4% lower than average; payments is 553822.9% higher than average; purchases is 499045.9% higher than average\n",
      "- Cluster 2: Health Cluster 2: credit_limit is 380969.4% higher than average; balance is 568.9% lower than average; cash_advance is 100.0% lower than average\n",
      "- Cluster 3: Health Cluster 3: cash_advance is 5846995.0% higher than average; payments is 124692.0% higher than average; purchases is 124472.8% higher than average\n"
     ]
    }
   ],
   "source": [
    "cluster_results_dict = {\n",
    "    \"spending\": cluster_results[0],\n",
    "    \"cash\": cluster_results[1],\n",
    "    \"payment\": cluster_results[2],\n",
    "    \"credit\": cluster_results[3],\n",
    "    \"health\": cluster_results[4],\n",
    "}\n",
    "\n",
    "for name in cluster_results_dict.keys():\n",
    "    joined = df.join(cluster_results_dict[name], on=\"cif_id\")\n",
    "    profiles, rel, desc = interpret_clusters(\n",
    "        joined,\n",
    "        id_col=\"cif_id\",\n",
    "        cluster_col=f\"{name}_cluster\",\n",
    "        feature_cols=cluster_configs[name][\"features\"],\n",
    "        cluster_name=name\n",
    "    )\n",
    "    print(f\"\\nðŸ“Š {name.upper()} CLUSTER INTERPRETATIONS:\")\n",
    "    for cid, d in desc.items():\n",
    "        print(f\"- Cluster {cid}: {d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aac41a-fdd8-47b3-a6fa-2b6f447827f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
